{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AccessWebData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1KFo3d-r_QNb5jahOS2vbmEklMuLQuKgD",
      "authorship_tag": "ABX9TyMuLOXKIBygMH1rhc221PDt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmkarPatkar/Coursera-Using_Python_to_Access_Web_Data/blob/master/AccessWebData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpVtEOjM6HbJ",
        "colab_type": "text"
      },
      "source": [
        "#**Using Python to Access Web Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIFUErFC6OZm",
        "colab_type": "text"
      },
      "source": [
        "**ASSIGNMENT OF WEEK 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrRSQGBK6grR",
        "colab_type": "text"
      },
      "source": [
        "**Extracting Data With Regular Expressions**\n",
        "\n",
        "**Finding Numbers in a Haystack**\n",
        "\n",
        "In this assignment you will read through and parse a file with text and numbers. You will extract all the numbers in the file and compute the sum of the numbers.\n",
        "\n",
        "data file: http://py4e-data.dr-chuck.net/regex_sum_506009.txt\n",
        "\n",
        "**Handling The Data**\n",
        "\n",
        "The basic outline of this problem is to read the file, look for integers using the re.findall(), looking for a regular expression of '[0-9]+' and then converting the extracted strings to integers and summing up the integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap8WvmFDv0Um",
        "colab_type": "code",
        "outputId": "e059b6e6-9891-4cea-fd57-a1d65ab7ff9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "\n",
        "op = open('/content/drive/My Drive/Colab Notebooks/regex_sum_506009.txt')\n",
        "sums = 0\n",
        "\n",
        "for li in op:\n",
        "    li = li.rstrip()\n",
        "    dig = re.findall('[0-9]+', li)\n",
        "    if not dig:\n",
        "        continue\n",
        "    else:\n",
        "        for digit in dig:\n",
        "            sums += int(digit)\n",
        "print(\"sum: \", sums)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sum:  420118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXbpTSrnISaE",
        "colab_type": "text"
      },
      "source": [
        "**ASSIGNMENT OF WEEK 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxZCwePRILpr",
        "colab_type": "text"
      },
      "source": [
        "**Understanding the Request / Response Cycle**\n",
        "\n",
        "**Exploring the HyperText Transport Protocol**\n",
        "\n",
        "You are to retrieve the following document using the HTTP protocol in a way that you can examine the HTTP Response headers.\n",
        "\n",
        "data file: http://data.pr4e.org/intro-short.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBrYD8uI9u9j",
        "colab_type": "code",
        "outputId": "68a828b7-b4ee-4c63-beb1-6608bd3188eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "import socket\n",
        "\n",
        "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "mysock.connect(('data.pr4e.org', 80))\n",
        "cmd = 'GET http://data.pr4e.org/intro-short.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
        "mysock.send(cmd)\n",
        "\n",
        "while True:\n",
        "    data = mysock.recv(512)\n",
        "    if len(data) < 1:\n",
        "        break\n",
        "    print(data.decode(),end='')\n",
        "\n",
        "mysock.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HTTP/1.1 200 OK\r\n",
            "Date: Fri, 29 May 2020 22:12:15 GMT\r\n",
            "Server: Apache/2.4.18 (Ubuntu)\r\n",
            "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\r\n",
            "ETag: \"1d3-54f6609240717\"\r\n",
            "Accept-Ranges: bytes\r\n",
            "Content-Length: 467\r\n",
            "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\r\n",
            "Pragma: no-cache\r\n",
            "Expires: Wed, 11 Jan 1984 05:00:00 GMT\r\n",
            "Connection: close\r\n",
            "Content-Type: text/plain\r\n",
            "\r\n",
            "Why should you learn to write programs?\n",
            "\n",
            "Writing programs (or programming) is a very creative \n",
            "and rewarding activity.  You can write programs for \n",
            "many reasons, ranging from making your living to solving\n",
            "a difficult data analysis problem to having fun to helping\n",
            "someone else solve a problem.  This book assumes that \n",
            "everyone needs to know how to program, and that once \n",
            "you know how to program you will figure out what you want \n",
            "to do with your newfound skills.  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-6PadkSTyWO",
        "colab_type": "text"
      },
      "source": [
        "**ASSIGNMENT OF WEEK 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydr7No-0SinY",
        "colab_type": "text"
      },
      "source": [
        "**Scraping HTML Data with BeautifulSoup**\n",
        "\n",
        "The program will use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file.\n",
        "\n",
        "data file: http://py4e-data.dr-chuck.net/comments_506011.html\n",
        "\n",
        "Data Format\n",
        "The file is a table of names and comment counts. You can ignore most of the data in the file except for lines like the following:\n",
        "\n",
        "```\n",
        "<tr><td>Modu</td><td><span class=\"comments\">90</span></td></tr>\n",
        "<tr><td>Kenzie</td><td><span class=\"comments\">88</span></td></tr>\n",
        "<tr><td>Hubert</ This is formatted as codetd><td><span class=\"comments\">87</span></td></tr>\n",
        "```\n",
        "\n",
        "You are to find all the <span> tags in the file and pull out the numbers from the tag and sum the numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsMcrpeVJNlD",
        "colab_type": "code",
        "outputId": "c06b2996-1d5c-4f1c-e748-3d51dbbf9505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import ssl\n",
        "\n",
        "# Ignore SSL certificate errors\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "url = input('Enter - ')\n",
        "html = urlopen(url, context=ctx).read()\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "sum = 0\n",
        "count = 0\n",
        "# Retrieve all of the span tags contents sum\n",
        "spans = soup('span')\n",
        "for span in spans:\n",
        "    sum += int(span.contents[0])\n",
        "    count += 1\n",
        "print('count:', count)\n",
        "print('sum:', sum)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter - http://py4e-data.dr-chuck.net/comments_506011.html\n",
            "count: 50\n",
            "sum: 2392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gHVTKOOUkyD",
        "colab_type": "text"
      },
      "source": [
        "**Assignment: Following Links in HTML Using BeautifulSoup**\n",
        "\n",
        "The program will use urllib to read the HTML from the data files below, extract the href= vaues from the anchor tags, scan for a tag that is in a particular position relative to the first name in the list, follow that link and repeat the process a number of times and report the last name you find.\n",
        "\n",
        "data file: http://py4e-data.dr-chuck.net/known_by_Ayshah.html\n",
        "\n",
        "Find the link at position 18 (the first name is 1). Follow that link. Repeat this process 7 times. The answer is the last name that you retrieve.\n",
        "Hint: The first character of the name of the last page that you will load is: B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiKjOmrQRVR5",
        "colab_type": "code",
        "outputId": "70e2fc40-00fb-49bc-c4df-a55859d4000d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import urllib.request, urllib.parse, urllib.error\n",
        "from bs4 import BeautifulSoup\n",
        "import ssl\n",
        "\n",
        "# Ignore SSL certificate errors\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "url = input('Enter - ')\n",
        "count = int(input('Enter count: ' ))\n",
        "position = int(input('Enter position: '))\n",
        "\n",
        "for i in range(count):\n",
        "    html = urllib.request.urlopen(url, context=ctx).read()\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "  # Retrieve all of the anchor tags\n",
        "    tags = soup('a')\n",
        "    link = []\n",
        "    text = []\n",
        "    for tag in tags:\n",
        "        a = tag.get('href', None)\n",
        "        link.append(a)\n",
        "        b = tag.text\n",
        "        text.append(b)\n",
        "    \n",
        "    print(link[position-1])\n",
        "    print(text[position-1])\n",
        "    url = link[position-1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter - http://py4e-data.dr-chuck.net/known_by_Ayshah.html\n",
            "Enter count: 7\n",
            "Enter position: 18\n",
            "http://py4e-data.dr-chuck.net/known_by_Janette.html\n",
            "Janette\n",
            "http://py4e-data.dr-chuck.net/known_by_Kirsten.html\n",
            "Kirsten\n",
            "http://py4e-data.dr-chuck.net/known_by_Celsi.html\n",
            "Celsi\n",
            "http://py4e-data.dr-chuck.net/known_by_Tobey.html\n",
            "Tobey\n",
            "http://py4e-data.dr-chuck.net/known_by_Camren.html\n",
            "Camren\n",
            "http://py4e-data.dr-chuck.net/known_by_Anesu.html\n",
            "Anesu\n",
            "http://py4e-data.dr-chuck.net/known_by_Brooke.html\n",
            "Brooke\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coUdQLoF8p0S",
        "colab_type": "text"
      },
      "source": [
        "**ASSIGNMENT OF WEEK 5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUOpOARt8sxm",
        "colab_type": "text"
      },
      "source": [
        "**Extracting Data from XML**\n",
        "\n",
        "The program will prompt for a URL, read the XML data from that URL using urllib and then parse and extract the comment counts from the XML data, compute the sum of the numbers in the file.\n",
        "\n",
        "data file: http://py4e-data.dr-chuck.net/comments_506013.xml\n",
        "\n",
        "**Data Format and Approach**\n",
        "\n",
        "The data consists of a number of names and comment counts in XML as follows:\n",
        "\n",
        "```\n",
        "<comment>\n",
        "  <name>Matthias</name>\n",
        "  <count>97</count>\n",
        "</comment>\n",
        "```\n",
        "You are to look through all the <comment> tags and find the <count> values sum the numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk3-AAUQb27X",
        "colab_type": "code",
        "outputId": "b08e34f9-e8c1-4ccb-eb6f-3905268af19a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import urllib\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "address = input(\"Enter location: \")\n",
        "print(\"Retrieving \", address)\n",
        "urlop = urllib.request.urlopen(address)\n",
        "data = urlop.read()\n",
        "print('Retrieved', len(data), 'characters')\n",
        "\n",
        "tree = ET.fromstring(data)\n",
        "\n",
        "results = tree.findall('.//comment')\n",
        "sum = 0\n",
        "count = 0\n",
        "for r in results:\n",
        "    a = int(r.find('count').text)\n",
        "    count += 1\n",
        "    sum += a\n",
        "print(\"count\", count)\n",
        "print(\"sum\", sum)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter location: http://py4e-data.dr-chuck.net/comments_506013.xml\n",
            "Retrieving  http://py4e-data.dr-chuck.net/comments_506013.xml\n",
            "Retrieved 4214 characters\n",
            "count 50\n",
            "sum 2679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McFRoYQdHc2k",
        "colab_type": "text"
      },
      "source": [
        "**ASSIGNMENT OF WEEK 6**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As-aKb_KHfI2",
        "colab_type": "text"
      },
      "source": [
        "**Extracting Data from JSON**\n",
        "\n",
        "The program will prompt for a URL, read the JSON data from that URL using urllib and then parse and extract the comment counts from the JSON data, compute the sum of the numbers in the file and enter the sum below:\n",
        "\n",
        "data file: http://py4e-data.dr-chuck.net/comments_506014.json\n",
        "\n",
        "**Data Format**\n",
        "The data consists of a number of names and comment counts in JSON as follows:\n",
        "\n",
        "```\n",
        "{\n",
        "  comments: [\n",
        "    {\n",
        "      name: \"Matthias\"\n",
        "      count: 97\n",
        "    },\n",
        "    {\n",
        "      name: \"Geomer\"\n",
        "      count: 97\n",
        "    }\n",
        "    ...\n",
        "  ]\n",
        "}\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OBigCyTE_-4",
        "colab_type": "code",
        "outputId": "52a61875-22c3-4516-b239-ae0adb9fb9d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import json\n",
        "import urllib\n",
        "\n",
        "address = input(\"Enter location: \")\n",
        "print(\"Retrieving \", address)\n",
        "\n",
        "url = urllib.request.urlopen(address)\n",
        "data = url.read()\n",
        "print('Retrieved', len(data), 'characters')\n",
        "\n",
        "info = json.loads(data)\n",
        "sum = 0\n",
        "count = 0\n",
        "for item in info['comments']:\n",
        "    a = item['count']\n",
        "    sum += a\n",
        "    count += 1\n",
        "print(\"count:\", count)\n",
        "print(\"sum:\", sum)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter location: http://py4e-data.dr-chuck.net/comments_506014.json\n",
            "Retrieving  http://py4e-data.dr-chuck.net/comments_506014.json\n",
            "Retrieved 2741 characters\n",
            "count: 50\n",
            "sum: 2247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxYACdn2MxTT",
        "colab_type": "text"
      },
      "source": [
        "**Using the GeoJSON API**\n",
        "\n",
        "**Calling a JSON API**\n",
        "\n",
        "The program will prompt for a location, contact a web service and retrieve JSON for the web service and parse that data, and retrieve the first place_id from the JSON. A place ID is a textual identifier that uniquely identifies a place as within Google Maps.\n",
        "API End Points\n",
        "\n",
        "To complete this assignment, you should use this API endpoint that has a static subset of the Google Data:\n",
        "\n",
        "data file: http://py4e-data.dr-chuck.net/json?\n",
        "\n",
        "To call the API, you need to include a key= parameter and provide the address that you are requesting as the address= parameter that is properly URL encoded using the urllib.parse.urlencode()\n",
        "\n",
        "**Turn In**\n",
        "\n",
        "Please run your program to find the place_id for this location:\n",
        "\n",
        "`Sharif University of Technology`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3i1fWYnbDEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "28b50b5b-4d7f-410f-f75e-fb37d5d92e1f"
      },
      "source": [
        "import urllib.request, urllib.parse, urllib.error\n",
        "import json\n",
        "import ssl\n",
        "\n",
        "api_key = 42\n",
        "serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
        "\n",
        "while True:\n",
        "    address = input('Enter location: ')\n",
        "    if len(address) < 1: break\n",
        "\n",
        "    parms = dict()\n",
        "    parms['address'] = address\n",
        "    if api_key is not False: parms['key'] = api_key\n",
        "    url = serviceurl + urllib.parse.urlencode(parms)\n",
        "\n",
        "    print('Retrieving', url)\n",
        "    uh = urllib.request.urlopen(url)\n",
        "    data = uh.read().decode()\n",
        "    print('Retrieved', len(data), 'characters')\n",
        "\n",
        "    try:\n",
        "        js = json.loads(data)\n",
        "    except:\n",
        "        js = None\n",
        "\n",
        "    if not js or 'status' not in js or js['status'] != 'OK':\n",
        "        print('==== Failure To Retrieve ====')\n",
        "        continue\n",
        "\n",
        "    place_id = js['results'][0]['place_id']\n",
        "    print(\"place id: \", place_id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter location: Sharif University of Technology\n",
            "Retrieving http://py4e-data.dr-chuck.net/json?address=Sharif+University+of+Technology&key=42\n",
            "Retrieved 1502 characters\n",
            "place id:  ChIJY34avKgAjj8RAYWHm5BaGgY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMrffmnmctHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}